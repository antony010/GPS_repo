{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Cities as FLows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "#for setting timestamp on output data\n",
    "import datetime\n",
    "#for createing and editing tables\n",
    "import pandas as pd\n",
    "#for creating spatial tables\n",
    "import geopandas as gpd\n",
    "#for maths operations\n",
    "import numpy as np\n",
    "#for loading in data from and querying postgres\n",
    "import sqlalchemy as db\n",
    "#for manipulating geometries\n",
    "from shapely.geometry import Point, LineString, box, mapping, Polygon\n",
    "#for the H3 hex grid \n",
    "from h3 import h3\n",
    "#for extracting osm data using a bounding region\n",
    "import pyrosm\n",
    "#for unsupervised learning\n",
    "import scipy.cluster.hierarchy as shc\n",
    "#for map visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "#for faster spatial indexing\n",
    "from sklearn.neighbors import BallTree\n",
    "#for machine learning preperation\n",
    "from sklearn import preprocessing\n",
    "#for importing the random forest\n",
    "import pickle\n",
    "#for loading in data from google cloud\n",
    "from google.cloud import storage\n",
    "import os\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ant-r\\Miniconda3\\envs\\gds\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3147: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#specifiy csv files to load into the process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate these as one large dataframe\n",
    "data = df1.append(df2).append(df3).append(df4).append(df5).append(df6).append(df7).append(df8).append(df9)\n",
    "#remove individual tables from cache\n",
    "del df1\n",
    "del df2\n",
    "del df3\n",
    "del df4\n",
    "del df5\n",
    "del df6\n",
    "del df7\n",
    "del df8\n",
    "del df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ant-r\\Miniconda3\\envs\\gds\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n",
      "C:\\Users\\ant-r\\Miniconda3\\envs\\gds\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n",
      "C:\\Users\\ant-r\\Miniconda3\\envs\\gds\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n"
     ]
    }
   ],
   "source": [
    "#hex_grid at zoom level 6 - for precalculated process\n",
    "# Read PostGIS database with Geopandas\n",
    "sql = 'SELECT * FROM public.hex_grid7;'\n",
    "hex_grid = gpd.read_postgis(sql=sql, con=con)\n",
    "hex_grid = hex_grid.rename(columns={'index':'hex_id'})\n",
    "\n",
    "# Read PostGIS database with Geopandas - for precalcualted process\n",
    "sql = 'SELECT * FROM public.hex_grid6;'\n",
    "hex_grid6 = gpd.read_postgis(sql=sql, con=con)\n",
    "hex_grid6 = hex_grid6.rename(columns={'index':'hex_id'})\n",
    "# Read PostGIS database for tranist ways\n",
    "sql = 'SELECT * from transit_way;'\n",
    "transit_way = gpd.read_postgis(sql=sql, con=con)\n",
    "\n",
    "# Read PostGIS database for transit relation\n",
    "sql = 'SELECT * FROM public.transit_relation;'\n",
    "transit_relation = gpd.read_postgis(sql=sql, con=con)\n",
    "train_relation = transit_relation[transit_relation['route']=='train']\n",
    "subway_relation = transit_relation[transit_relation['route']=='subway']\n",
    "rail_relation = transit_relation[transit_relation['route']=='railway']\n",
    "rail_relation = gpd.GeoDataFrame(rail_relation, crs='epsg:4326')\n",
    "subway_relation = gpd.GeoDataFrame(subway_relation, crs='epsg:4326')\n",
    "train_relation = gpd.GeoDataFrame(train_relation, crs='epsg:4326')\n",
    "rail_relation['transport_lin'] = 'rail_line'\n",
    "subway_relation['transport_lin'] = 'rail_line'\n",
    "train_relation['transport_lin'] = 'rail_line'\n",
    "\n",
    "# Read PostGIS database with bus routes\n",
    "sql = 'SELECT * FROM public.metro_bus_lines;'\n",
    "metro_bus_lines = gpd.read_postgis(sql=sql, con=con)\n",
    "metro_bus_relation = gpd.read_postgis(sql=sql, con=con)\n",
    "metro_bus_relation['transport_lin'] = 'bus_line'\n",
    "\n",
    "# Read PostGIS database with motorway features\n",
    "sql = 'SELECT * FROM public.motorway_washington;'\n",
    "transit_motorway_line = gpd.read_postgis(sql=sql, con=con)\n",
    "# Read PostGIS database with Geopandas\n",
    "sql = 'SELECT * FROM public.regional_bus_lines;'\n",
    "regional_bus_lines = gpd.read_postgis(sql=sql, con=con)\n",
    "regional_bus_relation = gpd.read_postgis(sql=sql, con=con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the geometry build a spatial dataframe\n",
    "data = gpd.GeoDataFrame(\n",
    "    data, geometry=gpd.points_from_xy(data.device_lon, data.device_lat))\n",
    "#generate a seperate lat and long\n",
    "data['device_lon'] = data.geometry.apply(lambda p: p.x)\n",
    "data['device_lat'] = data.geometry.apply(lambda p: p.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get distance between the GPS points\n",
    "def get_distance(lat, lng, lat_prev, lon_prev):\n",
    "    # Transform to radians\n",
    "    lng, lat, lon_prev, lat_prev = map(radians, [lng,  lat, lon_prev, lat_prev])\n",
    "    dist_longit = lon_prev - lng\n",
    "    dist_latit = lat_prev - lat\n",
    "    # Calculate area\n",
    "    area = sin(dist_latit/2)**2 + cos(lat) * cos(lat_prev) * sin(dist_longit/2)**2\n",
    "    # Calculate the central angle\n",
    "    central_angle = 2 * asin(sqrt(area))\n",
    "    radius = 3956 # Use 6371 for km\n",
    "    # Calculate Distance\n",
    "    distance = central_angle * radius\n",
    "    return abs(round(distance, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest(src_points, candidates, k_neighbors=1):\n",
    "    \"\"\"Find nearest neighbors for all source points from a set of candidate points\"\"\"\n",
    "\n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='haversine')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    # Get closest indices and distances (i.e. array at index 0)\n",
    "    # note: for the second closest points, you would take index 1, etc.\n",
    "    closest = indices[0]\n",
    "    closest_dist = distances[0]\n",
    "\n",
    "    # Return indices and distances\n",
    "    return (closest, closest_dist)\n",
    "\n",
    "\n",
    "def nearest_neighbor(left_gdf, right_gdf, return_dist=False):\n",
    "    \"\"\"\n",
    "    For each point in left_gdf, find closest point in right GeoDataFrame and return them.\n",
    "    \n",
    "    NOTICE: Assumes that the input Points are in WGS84 projection (lat/lon).\n",
    "    \"\"\"\n",
    "    \n",
    "    left_geom_col = left_gdf.geometry.name\n",
    "    right_geom_col = right_gdf.geometry.name\n",
    "    \n",
    "    # Ensure that index in right gdf is formed of sequential numbers\n",
    "    right = right_gdf.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Parse coordinates from points and insert them into a numpy array as RADIANS\n",
    "    # Notice: should be in Lat/Lon format \n",
    "    left_radians = np.array(left_gdf[left_geom_col].apply(lambda geom: (geom.y * np.pi / 180, geom.x * np.pi / 180)).to_list())\n",
    "    right_radians = np.array(right[right_geom_col].apply(lambda geom: (geom.y * np.pi / 180, geom.x * np.pi / 180)).to_list())\n",
    "    \n",
    "    # Find the nearest points\n",
    "    # -----------------------\n",
    "    # closest ==> index in right_gdf that corresponds to the closest point\n",
    "    # dist ==> distance between the nearest neighbors (in meters)\n",
    "    \n",
    "    closest, dist = get_nearest(src_points=left_radians, candidates=right_radians)\n",
    "\n",
    "    # Return points from right GeoDataFrame that are closest to points in left GeoDataFrame\n",
    "    closest_points = right.loc[closest]\n",
    "    \n",
    "    # Ensure that the index corresponds the one in left_gdf\n",
    "    closest_points = closest_points.reset_index(drop=True)\n",
    "    \n",
    "    # Add distance if requested \n",
    "    if return_dist:\n",
    "        # Convert to meters from radians\n",
    "        earth_radius = 6371000  # meters\n",
    "        closest_points['distance'] = dist * earth_radius\n",
    "        \n",
    "    return closest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions returns a gridded bounding box (as a GeoDataFrame) using h3 or quadkeys\n",
    "def load_grid(grid_type, zoom, bbox):\n",
    "    list_hexagons = []\n",
    "    list_hex_id = []\n",
    "    if str.lower(grid_type) == 'h3' or str.lower(grid_type) == 'any':\n",
    "        list_hex_id = list(h3.polyfill(geojson = mapping(bbox), res = zoom, geo_json_conformant=True))\n",
    "        list_hexagons = list(map(lambda x : Polygon(h3.h3_to_geo_boundary(h=x, geo_json=True)), list_hex_id))\n",
    "    elif str.lower(grid_type) == 'qk':\n",
    "        bounds = bbox.bounds\n",
    "        list_hex_id = list(map(mercantile.quadkey, \n",
    "                               mercantile.tiles(bounds[0], bounds[1], bounds[2], bounds[3], zooms=zoom)))\n",
    "        list_hexagons = list(map(lambda x:box(*mercantile.bounds(x)),\n",
    "                                 mercantile.tiles(bounds[0], bounds[1], bounds[2], bounds[3], zooms=zoom)))\n",
    "    \n",
    "    grid = pd.DataFrame({'hex_id': list_hex_id, 'geometry':list_hexagons})\n",
    "    grid = gpd.GeoDataFrame(grid, crs='epsg:4326')\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_line(row):\n",
    "    \"\"\"\n",
    "    This function takes all OSM rail features and and labels them as a 'train_line'.\n",
    "    \n",
    "    \"\"\"\n",
    "    if row['route']=='subway':\n",
    "        val = 'train_line'\n",
    "    elif row['route']=='railway':\n",
    "        val = 'train_line'\n",
    "    elif row['route']=='train':\n",
    "        val = 'train_line'\n",
    "    elif row['railway']=='rail':\n",
    "        val = 'train_line'\n",
    "    else:\n",
    "        val = None\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break out multipart string\n",
    "def multi2single(gpdf):\n",
    "    gpdf_singleline = gpdf[gpdf.geometry.type == 'LineString']\n",
    "    gpdf_multiline = gpdf[gpdf.geometry.type == 'MultiLineString']\n",
    "\n",
    "    for i, row in gpdf_multiline.iterrows():\n",
    "        Series_geometries = pd.Series(row.geometry)\n",
    "        df = pd.concat([gpd.GeoDataFrame(row, crs=gpdf_multiline.crs).T]*len(Series_geometries), ignore_index=True)\n",
    "        df['geometry']  = Series_geometries\n",
    "        gpdf_singleline = pd.concat([gpdf_singleline, df])\n",
    "\n",
    "    gpdf_singleline.reset_index(inplace=True, drop=True)\n",
    "    return gpdf_singleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function densifys the line feature creating many vertices at the step size of choice\n",
    "def densify_geometry (line_geometry, step, crs=None):\n",
    "        \n",
    "        #crs: epsg code of a coordinate reference system you want your line to be georeferenced with\n",
    "        # step: add a vertice every step in whatever unit your coordinate reference system use.\n",
    "    \n",
    "        length_m=line_geometry.length # get the length\n",
    "    \n",
    "        xy=[] # to store new tuples of coordinates\n",
    "    \n",
    "        for distance_along_old_line in np.arange(0,(length_m),step): \n",
    "    \n",
    "            point = line_geometry.interpolate(distance_along_old_line) # interpolate a point every step along the old line\n",
    "            xp,yp = point.x, point.y # extract the coordinates\n",
    "    \n",
    "            xy.append((xp,yp)) # and store them in xy list\n",
    "    \n",
    "        new_line=LineString(xy) # Here, we finally create a new line with densified points.\n",
    "        \n",
    "        if crs != None:  #  If you want to georeference your new geometry, uses crs to do the job.\n",
    "            new_line_geo=gpd.geoseries.GeoSeries(new_line,crs=crs) \n",
    "            return new_line_geo\n",
    "    \n",
    "        else:\n",
    "            return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the list of columns \n",
    "col_list = ['identifier', 'timestamp',\\\n",
    "                       'source_id',\\\n",
    "                       'device_lon',\\\n",
    "                       'device_lat',\\\n",
    "                       'device_horizontal_accuracy',\\\n",
    "                       'province_short', \\\n",
    "                       'time_zone_name'#, \\\n",
    "                       #'gid'\n",
    "           ]\n",
    "\n",
    "data = data[col_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append additional variables to original data feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes error on copy of a slice\n",
    "data = data.copy()\n",
    "#rename the attribution\n",
    "data.rename(columns={'identifier':'uid', 'source_id': 'aid','device_lon':'longitude', 'device_lat':'latitude','device_horizontal_accuracy':'accuracy', 'province_short':'state', 'time_zone_name':'time_zone'},inplace=True)\n",
    "#edit the feature types of those that are incorrectly strings\n",
    "data['longitude'] = data['longitude'].astype(float)\n",
    "data['latitude'] = data['latitude'].astype(float)\n",
    "data['accuracy'] = data['accuracy'].astype(float)\n",
    "# Calculate the corresponding h3id and the geometry associated to it (changed to 9 to evaluate difference)\n",
    "data['hex_id'] = list(map(lambda p : h3.geo_to_h3(p[1], p[0], resolution=8), data[['longitude', 'latitude']].values))\n",
    "data['hex_geom'] = list(map(lambda x : Polygon(h3.h3_to_geo_boundary(h=x, geo_json=True)), data['hex_id'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes error on copy of a slice\n",
    "data = data.copy()\n",
    "#group data by the uidand count the number of hex polygons at zoom level 8 it intersects\n",
    "data_grouped = data.groupby('uid').agg({'hex_id':'nunique'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more than 4 hex grids must be traversed - removes stationary devices\n",
    "more_than_4 = data_grouped[data_grouped['hex_id']>=4]\n",
    "#rename hex feature\n",
    "more_than_4 = more_than_4.rename(columns={'hex_id':'hex_id_n'})\n",
    "#reindex\n",
    "more_than_4 = more_than_4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edit the datatypes\n",
    "data['uid'] = data['uid'].astype(str)\n",
    "more_than_4['uid'] = more_than_4['uid'].astype(str)\n",
    "more_than_4['hex_id_n'] = more_than_4['hex_id_n'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dat ais only retained when it has more than for hex ids\n",
    "data = more_than_4.set_index('uid').join(data.set_index('uid'), how='inner', rsuffix='_other')\n",
    "# Filter pings based on accuracy\n",
    "data = data[data['accuracy']<50] \n",
    "#set the time to be America/Neyyork \n",
    "data['datetime'] = data.apply(lambda row: pd.Timestamp(row['timestamp'], tz='America/New_York'), axis = 1)\n",
    "#set the datetime\n",
    "data['timestamp'] = data.apply(lambda row: pd.to_datetime(row['timestamp'], origin='unix'), axis = 1)\n",
    "data = data.reset_index()\n",
    "#remove any duplicate values\n",
    "data = data.drop_duplicates(subset=['uid', 'aid', 'longitude', 'latitude', 'timestamp', 'accuracy'])\n",
    "#remove any null values\n",
    "data = data.dropna(subset=['uid', 'timestamp', 'aid', 'latitude', 'longitude', 'accuracy', 'state', 'time_zone', 'datetime'])\n",
    "#return the hour\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "#return the day of the week\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek\n",
    "#return the day of the year\n",
    "data['dayofyear'] = data['datetime'].dt.dayofyear\n",
    "#return the order of the event poitns\n",
    "data['rank'] = data.groupby('uid')['timestamp'].rank(ascending=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate variables from the previous point feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the values by their rank and within each unique user\n",
    "data = data.sort_values([\"uid\", \"rank\"], ascending = (False, True))\n",
    "#attain the longitude of the preious\n",
    "data['latitude_prev'] = data.groupby(['uid'])['latitude'].shift(1)\n",
    "#attain the latiudue of the previous\n",
    "data['longitude_prev'] = data.groupby(['uid'])['longitude'].shift(1)\n",
    "#attain the timestamp of the previous\n",
    "data['timestamp_prev'] = data.groupby(['uid'])['timestamp'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the timestamp of the previous to be unix datetime\n",
    "data['timestamp_prev'] = data.apply(lambda row: pd.to_datetime(row['timestamp_prev'], origin='unix'), axis = 1)\n",
    "#calulate the distance between the current and previous GPS point\n",
    "data['great_circle'] = data.apply(lambda row: get_distance(row['latitude'], row['longitude'], row['latitude_prev'], row['longitude_prev']), axis = 1)\n",
    "#get the second difference between the current and previous point\n",
    "data['sec_diff'] = data['timestamp'] - data['timestamp_prev']\n",
    "#set these to be seconds\n",
    "data['sec_diff'] = data['sec_diff'] / np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set all the null values from this to be zero\n",
    "data[['sec_diff']] = data[['sec_diff']].fillna(value=0)\n",
    "#speed calc\n",
    "data['velo'] = data['great_circle']/data['sec_diff']\n",
    "#fill the null values as zero\n",
    "data[['velo']] = data[['velo']].fillna(value=0)\n",
    "#reset index\n",
    "data = data.reset_index(drop=True)\n",
    "#velo times 60 to get mph\n",
    "data['velo'] = (data['velo']*60)*60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a trend like to find consectuve hex ids\n",
    "data['trend'] = data.uid.groupby(data.hex_id.ne(data.hex_id.shift()).cumsum()).cumcount()\n",
    "#grouped = data.groupby('uid')\n",
    "data[\"tripID\"] = \"\"\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.3712925910949707\n"
     ]
    }
   ],
   "source": [
    "#define a vectorised condition that breaks the sequence into a trip when the velcity is greater than 75mph, there are more than 3 GPS points in the same zoom level 8 hex\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "data['condition'] = (data['sec_diff']> 400) | (data['trend']>=3)| (data['velo']>75)\n",
    "\n",
    "data['tripID'] = data.groupby('uid')['condition'].cumsum()\n",
    "\n",
    "data['tripID'] += 1\n",
    "\n",
    "print('Elapsed time:', time.time()- start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as the current trip ids are a series of numbers append the trip id to the user id to establish the trip number\n",
    "data['tripID'] = data['tripID'].astype(int)\n",
    "data['U_trip_ID'] = data[\"uid\"].astype(str) +'-'+ data[\"tripID\"].astype(str)\n",
    "#establish the number of unique trip ids\n",
    "counts = data['U_trip_ID'].value_counts()\n",
    "#only bring through when there is at least more than 3 vertices on a trip\n",
    "data = data[data['U_trip_ID'].isin(counts.index[counts >= 3])]\n",
    "#establish new features (duplicates) to be edited whilst retaining the original\n",
    "data['time_calc'] = data['sec_diff']\n",
    "data['full_dist'] = data['great_circle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first value in the trip must have a value of 0 for the distance and the time value \n",
    "data.loc[data.groupby('U_trip_ID')['sec_diff'].head(1).index, 'time_calc'] = 0\n",
    "data.loc[data.groupby('U_trip_ID')['great_circle'].head(1).index, 'full_dist'] = 0\n",
    "#create a lookup table groupby the unque trip ids and gain the full trip duration and distane and count of vertices\n",
    "lookup = data.groupby(['U_trip_ID']).agg({'time_calc' : 'sum', 'full_dist': 'sum', 'U_trip_ID' : 'count'})\n",
    "#rename the lookup table attributes\n",
    "lookup = lookup.rename(columns={'U_trip_ID':'count_pts', 'time_calc':'total_trip_time', 'full_dist':'overall_full_dist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each of the individual point features append the details of the full trip\n",
    "data = pd.merge(data, lookup, left_on = 'U_trip_ID', right_index=True, how = 'left')\n",
    "#make data a geodataframe once more\n",
    "data = gpd.GeoDataFrame(\n",
    "    data, geometry=gpd.points_from_xy(data.longitude, data.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create line features from the trip IDs appending values to a list\n",
    "trip_line = data.groupby(['U_trip_ID'])['geometry'].apply(lambda x: LineString(x.tolist()))\n",
    "#make the line feature a geometry\n",
    "trip_line = gpd.GeoDataFrame(trip_line, geometry='geometry')\n",
    "trip_line = trip_line.reset_index()\n",
    "#make time an integer\n",
    "data['time_calc'] = data['time_calc'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial feature Context "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### motorway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ant-r\\Miniconda3\\envs\\gds\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ant-r\\Miniconda3\\envs\\gds\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "transit_motorway_line = gpd.GeoDataFrame(transit_motorway_line, crs='epsg:4326')\n",
    "#transit_motorway_line['transport_poi'] = 'motorway'\n",
    "transit_motorway_line['transport_lin'] = 'motorway_line'\n",
    "transit_motorway_line = gpd.GeoDataFrame(transit_motorway_line, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Railway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ant-r\\Miniconda3\\envs\\gds\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n",
      "  \n",
      "C:\\Users\\ant-r\\Miniconda3\\envs\\gds\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set the rail features to be trains\n",
    "transit_relation['trns_type'] = transit_relation.apply(f_line, axis=1)\n",
    "#filter only required columns\n",
    "transit_relation = transit_relation[['id','trns_type','geom']]\n",
    "#esnure all are trains\n",
    "transit_relation = transit_relation[transit_relation['trns_type']=='train_line']\n",
    "#label way features as train lines\n",
    "transit_way['trns_type'] = transit_way.apply(f_line, axis=1)\n",
    "#filter only required columns\n",
    "transit_way = transit_way[['id','trns_type','geom']]\n",
    "#ensure all ways are trains\n",
    "transit_way = transit_way[transit_way['trns_type']=='train_line']\n",
    "#join the ways to the realtions to get completed train route\n",
    "transit_relation = transit_relation.append(transit_way)\n",
    "#rename geometry\n",
    "transit_relation = transit_relation.rename(columns={'geom': 'geometry'})\n",
    "#set as a geodataframe\n",
    "transit_relation = gpd.GeoDataFrame(transit_relation, crs='epsg:4326')\n",
    "#make all multpart features singlepart\n",
    "transit_relation = multi2single(transit_relation)\n",
    "#transit_relation = transit_relation[transit_relation['trns_type'] == 'train_line']\n",
    "#remove short sections of the train line\n",
    "transit_relation = transit_relation[transit_relation.geometry.length > 0.0001]\n",
    "#densify the railway line geometry for distance calcs\n",
    "transit_relation['geometry'] = transit_relation.geometry.apply(densify_geometry, step=0.0001, crs = None)\n",
    "#transport line into a list of points\n",
    "transit_relation['point_list'] = transit_relation['geometry'].apply(lambda geom : list(geom.coords))\n",
    "# Need to cast to DataFrame because the explode method for a GeoDataFrame means something different\n",
    "#explode the points list into a record for each point\n",
    "transit_relation = pd.DataFrame(transit_relation).explode('point_list')\n",
    "# Transform lat/lon tuple into Point geometry\n",
    "transit_relation['point_list'] = transit_relation['point_list'].apply(lambda coor : Point(*coor))\n",
    "# Need to turn it into a GeoDataFrame again\n",
    "transit_relation = gpd.GeoDataFrame(transit_relation, crs='epsg:4326')\n",
    "#reset the geoemtry to be the new point\n",
    "transit_relation = transit_relation.set_geometry('point_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a string for each bus feature to label on intersection\n",
    "regional_bus_lines['trns_type'] = 'bus_line'\n",
    "#filter only sttributes required\n",
    "regional_bus_lines = regional_bus_lines[['id','trns_type','geom']]\n",
    "#rename the geometry\n",
    "regional_bus_lines = regional_bus_lines.rename(columns={'geom': 'geometry'})\n",
    "#make bus lines a geodataframe\n",
    "regional_bus_lines = gpd.GeoDataFrame(regional_bus_lines, crs='epsg:4326')\n",
    "#make these single part features\n",
    "regional_bus_lines = multi2single(regional_bus_lines)\n",
    "#densify the bus route line features\n",
    "regional_bus_lines = regional_bus_lines[regional_bus_lines.geometry.length > 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create string for each inner city bus line\n",
    "metro_bus_lines['trns_type'] = 'bus_line'\n",
    "#alter the name of the unique identfier\n",
    "metro_bus_lines = metro_bus_lines.rename(columns={'objectid': 'id'})\n",
    "#filter to only keep variables required\n",
    "metro_bus_lines = metro_bus_lines[['id','trns_type','geom']]\n",
    "#rename geometry column\n",
    "metro_bus_lines = metro_bus_lines.rename(columns={'geom': 'geometry'})\n",
    "#change to geoedataframe\n",
    "metro_bus_lines = gpd.GeoDataFrame(metro_bus_lines, crs='epsg:4326')\n",
    "#change multpart to single part\n",
    "metro_bus_lines = multi2single(metro_bus_lines)\n",
    "#density the bus line feature (this was for the old euclidean distacne calcs on buses)\n",
    "metro_bus_lines = metro_bus_lines[metro_bus_lines.geometry.length > 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join inner city bus lines to regional bus routes\n",
    "metro_bus_lines = regional_bus_lines.append(metro_bus_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_bus_relation = gpd.GeoDataFrame(metro_bus_lines, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_bus_relation.rename(columns={'geom':'geometry', 'objectid':'id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the points of the bus route to a list\n",
    "metro_bus_lines['point_list'] = metro_bus_lines['geometry'].apply(lambda geom : list(geom.coords))\n",
    "# Need to cast to DataFrame because the explode \n",
    "metro_bus_lines = pd.DataFrame(metro_bus_lines).explode('point_list')\n",
    "# Transform lat/lon tuple into Point geometry\n",
    "metro_bus_lines['point_list'] = metro_bus_lines['point_list'].apply(lambda coor : Point(*coor))\n",
    "# Need to turn it into a GeoDataFrame again\n",
    "metro_bus_lines = gpd.GeoDataFrame(metro_bus_lines, crs='epsg:4326')\n",
    "#set the geoemtry to the points of the bus routes (for distance calculations - not used in final version)\n",
    "metro_bus_lines = metro_bus_lines.set_geometry('point_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate distances for Train line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distance between points in meters, to the train line\n",
    "closest_lines = nearest_neighbor(data, transit_relation, return_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eranme the distance to be dist_trns_ln, and then rename the trns_type to be a trns_line_type\n",
    "closest_lines = closest_lines.rename(columns={'trns_type':'trs_line_type' })\n",
    "closest_lines = closest_lines.rename(columns={'distance':'dist_trns_line' })\n",
    "# Rename the geometry of closest stops gdf so that we can easily identify it\n",
    "closest_lines = closest_lines.rename(columns={'point_list': 'closest_line_geom'})\n",
    "#drop the original line geoemtry on the closest line dataframe\n",
    "closest_lines = closest_lines.drop('geometry',axis=1,inplace=False)\n",
    "#drop the id as no longer required\n",
    "closest_lines = closest_lines.drop('id',axis=1,inplace=False)\n",
    "#join the attribute for the distance to the closest train geometry\n",
    "data = data.join(closest_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Georeferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get h3 grid at zoom level 8\n",
    "bbox = box(-78.344,37.986,-75.730,39.671)\n",
    "#load h3_grid\n",
    "h3_grid = load_grid('h3',8,bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_bus_relation['transport_lin'] = 'bus_line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the geometry column\n",
    "train_relation.rename(columns={'geom':'geometry'},inplace=True)\n",
    "transit_motorway_line.rename(columns={'geom':'geometry'},inplace=True)\n",
    "#list columns to keep\n",
    "col_list2 = ['transport_lin', 'geometry',\\\n",
    "                       'id']\n",
    "#filter only columns that are required\n",
    "train_relation = train_relation[col_list2]\n",
    "metro_bus_relation = metro_bus_relation[col_list2]\n",
    "transit_motorway_line = transit_motorway_line[col_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append all spatial context features into one geodataframe\n",
    "ll = train_relation.append(metro_bus_relation).append(transit_motorway_line)\n",
    "ll = gpd.GeoDataFrame(ll, crs='epsg:4326')\n",
    "ll.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make h3 grid_list a geodataframe\n",
    "h3_grid = gpd.GeoDataFrame(h3_grid, crs='epsg:4326')\n",
    "#do a spatial join on the h3 grid (zoom level 8)\n",
    "h3_grid_line = gpd.sjoin(h3_grid, ll, how='inner', op='intersects')\n",
    "#produce a dataframe merge of the features that the h3 grid intersects\n",
    "list_of_feat_lin = h3_grid.merge(h3_grid_line, on='hex_id').groupby(['hex_id']).agg({'transport_lin':list}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only one of the features names in the collection as a set of a possible 3\n",
    "list_of_feat_lin['transport_lin'] = list_of_feat_lin.apply(lambda row: list(set(row['transport_lin'])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_grid['geometry'].intersects(ll['geometry'].values[0])\n",
    "#add the list feature to the original geodataframe of points\n",
    "data = data.merge(list_of_feat_lin, on='hex_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make timestamp variables string for later extract to shapefile\n",
    "data['timestamp_prev'] = data['timestamp_prev'].astype(str)\n",
    "data['datetime'] = data['datetime'].astype(str)\n",
    "data['timestamp'] = data['timestamp'].astype(str)\n",
    "#data['transport_lin'] = data['transport_lin'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a boolean column to indicate the presence of a spatial feature\n",
    "data['bus_line'] = np.where(data['transport_lin'].str.contains(\"bus_line\"),1,0)\n",
    "data['rail_line'] = np.where(data['transport_lin'].str.contains(\"rail_line\"),1,0)\n",
    "data['motorway_line'] = np.where(data['transport_lin'].str.contains(\"motorway_line\"),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define where the start of the jounery is (for possible use in closeness to bus-stops or train stations)\n",
    "data['start'] = np.where(data['time_calc'] == 0, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added to stop kickbacks and jumps in distance\n",
    "data['velo'] = np.where(data['time_calc'] == 0, 0, data['velo'])\n",
    "#make the distance 0 at the start of the journey as well as the time\n",
    "data['great_circle'] = np.where(data['time_calc'] == 0, 0, data['great_circle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the GPS point is in 15 metres of the train line feature, create a value of in_range\n",
    "data['in_range']= data.apply(lambda row: 1 if (row['dist_trns_line'] <= 15) else 0, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to attain the standard deviation\n",
    "def std(x): \n",
    "    return np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group the Trip features - Create attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the trip feature with attributes defined\n",
    "trips = data.groupby(['U_trip_ID']).agg({'total_trip_time':'first', 'overall_full_dist': 'first', 'count_pts' : 'first', 'bus_line':'sum', 'rail_line':'sum', 'motorway_line':'sum', 'velo':['mean', std, 'max'], 'dist_trns_line':['mean', 'min', 'max'],'in_range':'sum', 'hour':'first', 'dayofweek':'first', 'dayofyear':'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete data from cache\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create likelihood values\n",
    "trips['train_conf'] = (trips['rail_line']['sum']/trips['count_pts']['first']).replace(np.inf, 0)\n",
    "trips['bus_conf'] = (trips['bus_line']['sum']/trips['count_pts']['first']).replace(np.inf, 0)\n",
    "trips['motorway_conf'] = (trips['motorway_line']['sum']/trips['count_pts']['first']).replace(np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a merge on the unique trip id with the \n",
    "trips = trips.merge(trip_line, on='U_trip_ID', how= 'left')\n",
    "#make into geodataframe\n",
    "trips = gpd.GeoDataFrame(trips, geometry='geometry')\n",
    "#replace infiity values with zero\n",
    "trips[('velo', 'mean')] = trips[('velo', 'mean')].replace(np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace infinite values with zero\n",
    "trips[('velo', 'max')] = trips[('velo', 'max')].replace(np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename attributes to more logical names\n",
    "trips = trips.rename(columns={('velo', 'mean') : \"velo_mean\", ('train_conf', ''): \"train_conf\", ('bus_conf', ''): \"bus_conf\", ('dist_trns_line', 'mean'):\"dist_trns_line\",('dist_trns_line', 'max'):\"max_dist_trns\",('dist_trns_line', 'min'):\"min_dist_trns\", ('velo', 'max'):\"max_velo\",('velo', 'std'):\"std_velo\", ('overall_full_dist', 'first'):'overall_full_dist', ('total_trip_time', 'first'):'total_trip_time', ('closest_stp_dst', 'mean'):'closest_stp_dst', ('closest_busstp_dst', 'mean'):'closest_busstp_dst', ('dist_trns_busline', 'mean'):'dist_trns_busline',('motorway_conf', ''): \"motorway_conf\", ('in_range', 'sum'):'in_range', ('hour', 'first'):'hour', ('dayofweek', 'first'):'dayofweek', ('dayofyear', 'first'):'dayofyear'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure that trips are not 0 distance\n",
    "trips = trips[trips['overall_full_dist']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version of the trip features ready for extraction\n",
    "tripsA= trips.loc[:, ['total_trip_time', 'overall_full_dist','train_conf', 'velo_mean','max_velo', 'bus_conf','motorway_conf','in_range','std_velo','dist_trns_line','geometry']]\n",
    "tripsA = gpd.GeoDataFrame(tripsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Based Classifier - Label Trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the rule to identify trains\n",
    "def trains_(row):\n",
    "    if (row['train_conf']>=0.55) and (((row['in_range']>=2) and (row['dist_trns_line']<=110))|(row['dist_trns_line']<=40)|(row['in_range']>=4)) and (row['velo_mean']>=10) and (row['max_velo']>=15)and (row['std_velo']>=6):\n",
    "        val = 6     \n",
    "    else:\n",
    "        val = None\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the train rule and add labels to the features identified as trains\n",
    "trips['labels'] = trips.apply(trains_, axis=1)\n",
    "#make time minutes\n",
    "trips['total_trip_time']= trips['total_trip_time']/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break apart the features already labeled with those that are not\n",
    "walk_and_train = trips[trips.labels.notnull()]\n",
    "cars_and_rest = trips[trips.labels.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full list of attribution to be retained\n",
    "data = trips.loc[:, ['total_trip_time', 'overall_full_dist', 'velo_mean','max_velo', 'std_velo','train_conf','bus_conf','train_conf','in_range','motorway_conf','dist_trns_line']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribution used in the final version of the random forest \n",
    "X = cars_and_rest[['velo_mean','max_velo','std_velo','bus_conf','motorway_conf','overall_full_dist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model to compare the results\n",
    "model_rf = pickle.load(open('model_rf7_fresh.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_and_rest = cars_and_rest.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_and_rest['labels'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Average Values - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = cars_and_rest.loc[:, ['total_trip_time', 'overall_full_dist','train_conf', 'velo_mean','max_velo', 'bus_conf','motorway_conf','in_range','std_velo','dist_trns_line']].groupby(predictions)\n",
    "g.size()\\\n",
    " .sort_values()\n",
    "#generate the average\n",
    "g2 = g.mean()\n",
    "#round to 2 decimal places\n",
    "g2 = g2.round(2)\n",
    "#rename axis with Table 1 label\n",
    "g2 = g2.rename_axis('TABLE 2 - RF MATRIX', axis=1)\n",
    "g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append tables\n",
    "trips = walk_and_train.append(cars_and_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display average values - Both Rules and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = trips.loc[:, ['total_trip_time', 'overall_full_dist','train_conf', 'velo_mean','max_velo', 'bus_conf','motorway_conf','in_range','std_velo','dist_trns_line']].groupby(trips['labels'])\n",
    "g.size()\\\n",
    " .sort_values()\n",
    "#generate the average\n",
    "g2 = g.mean()\n",
    "#round to 2 decimal places\n",
    "g2 = g2.round(2)\n",
    "#rename axis with Table 1 label\n",
    "g2 = g2.rename_axis('TABLE 2 - RF MATRIX', axis=1)\n",
    "g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['labels'] = trips['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for extractions\n",
    "tripsA = trips.loc[:, ['U_trip_ID','total_trip_time', 'overall_full_dist', 'velo_mean','max_velo', 'train_conf','bus_conf','std_velo','min_dist_trns', 'dist_trns_line','geometry','labels','hour','dayofweek','dayofyear']]\n",
    "tripsA = gpd.GeoDataFrame(tripsA, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process to label the days from numbers to strings\n",
    "days = {0:'Mon',1:'Tues',2:'Weds',3:'Thurs',4:'Fri',5:'Sat',6:'Sun'}\n",
    "cats = [ 'Mon', 'Tues', 'Weds', 'Thurs', 'Fri', 'Sat', 'Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the process to label days\n",
    "trips['dayofweek'] = trips['dayofweek'].apply(lambda x: days[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_type = CategoricalDtype(categories=cats, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['dayofweek'] = trips['dayofweek'].astype(cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = trips.rename(columns={('dayofweek', 'first') : \"dayofweek\", ('hour', 'first') : \"hour\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsA = gpd.GeoDataFrame(tripsA, crs='epsg:4326')\n",
    "g = trips.groupby(['dayofweek','hour']).agg({'U_trip_ID':'count'})\n",
    "g = g.reset_index().pivot(index='hour', columns='dayofweek', values='U_trip_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Temporal Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = trips.groupby(['labels','dayofweek','hour']).agg({'U_trip_ID':'count'})\n",
    "h = h.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for breaking apart the trips by transport mode to display as a heatmap\n",
    "h1 = h[h['labels']==1].pivot(index='hour', columns='dayofweek', values='U_trip_ID')\n",
    "h3 = h[h['labels']==3].pivot(index='hour', columns='dayofweek', values='U_trip_ID')\n",
    "h6 = h[h['labels']==6].pivot(index='hour', columns='dayofweek', values='U_trip_ID')\n",
    "h4 = h[h['labels']==4].pivot(index='hour', columns='dayofweek', values='U_trip_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#create overall weekly heatmap\n",
    "fig4 = plt.figure(figsize=(8, 8))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(g, cmap=\"Greens\")\n",
    "#fig4.savefig(\"temporal_all_washFINAL.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate figure size as 15x16\n",
    "fig4 = plt.figure(figsize=(15, 16))\n",
    "#layout 2cols by 3rows\n",
    "spec4 = fig4.add_gridspec(ncols=2, nrows=2)\n",
    "\n",
    "#generate subplots in formation\n",
    "f4_ax1 = fig4.add_subplot(spec4[0, 0])\n",
    "f4_ax2 = fig4.add_subplot(spec4[0, 1])\n",
    "f4_ax3 = fig4.add_subplot(spec4[1, 0])\n",
    "f4_ax4 = fig4.add_subplot(spec4[1, 1])\n",
    "\n",
    "sns.heatmap(h1, cmap=\"Blues\", ax = f4_ax1)\n",
    "sns.heatmap(h3, cmap=\"Blues\", ax = f4_ax2)\n",
    "sns.heatmap(h6, cmap=\"Blues\", ax = f4_ax3)\n",
    "sns.heatmap(h4, cmap=\"Blues\", ax = f4_ax4)\n",
    "\n",
    "f4_ax1.set_title('Walking')\n",
    "f4_ax2.set_title('Bus')\n",
    "f4_ax3.set_title('Train')\n",
    "f4_ax4.set_title('Car')\n",
    "\n",
    "fig4.suptitle(\"Figure 2 - Temporal Heatmaps per transport mode \" ,\n",
    "                 fontsize=14, fontweight='bold'\n",
    "                  )\n",
    "fig4.savefig(\"temporal_modes_washFINAL.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Origin Destination Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['labels'] = trips['labels'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_of_trans(row):\n",
    "    if row['labels'] == '1':\n",
    "        val = 'walk'\n",
    "    elif row['labels'] == '3':\n",
    "        val = 'bus'\n",
    "    elif row['labels'] == '4':\n",
    "        val = 'car'\n",
    "    else:\n",
    "        val = 'train'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['labels'] = trips.apply(mode_of_trans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a centroid point on the hex polygons\n",
    "hex_grid['centroid'] = hex_grid.geometry.centroid\n",
    "hex_grid6['centroid'] = hex_grid6.geometry.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make a line a point for the origin point of the trip\n",
    "def linestring_to_points(line):\n",
    "    return line.coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsA = gpd.GeoDataFrame(tripsA, geometry ='geometry' , crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make a line a point for the destination point of the trip\n",
    "def linestring_to_points_end(line):\n",
    "    return line.coords[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables fo the end of the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsA['end_points'] = tripsA.apply(lambda l: linestring_to_points_end(l['geometry']),axis=1)\n",
    "trips_end = tripsA.loc[:,['U_trip_ID','end_points']]\n",
    "trips_end.rename(columns = {'end_points':'geometry'}, inplace = True)\n",
    "trips_end['geometry']=gpd.points_from_xy(trips_end['geometry'].str[0], trips_end['geometry'].str[1])\n",
    "trips_end = gpd.GeoDataFrame(trips_end, geometry='geometry', crs=\"EPSG:4326\")\n",
    "trips_end = gpd.sjoin(trips_end, hex_grid, how=\"inner\", rsuffix=\"7\" )\n",
    "trips_end = trips_end.loc[:, trips_end.columns != 'index_7']\n",
    "trips_end = gpd.sjoin(trips_end, hex_grid6, how=\"inner\", rsuffix=\"6\" )\n",
    "trips_end = trips_end.loc[:, trips_end.columns != 'index_6']\n",
    "trips_end = trips_end.rename(columns={'hex_id_left':'hex_id_7', 'centroid_left':'centroid_7'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables for the start of the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsA['start_points'] = tripsA.apply(lambda l: linestring_to_points(l['geometry']),axis=1)\n",
    "trips_start = tripsA.loc[:,['U_trip_ID','total_trip_time','overall_full_dist','velo_mean','train_conf','bus_conf','min_dist_trns','dist_trns_line','labels','start_points','geometry','hour','dayofweek']]\n",
    "trips_start['start_points']=gpd.points_from_xy(trips_start['start_points'].str[0], trips_start['start_points'].str[1])\n",
    "trips_start = gpd.GeoDataFrame(trips_start, geometry='start_points', crs=\"EPSG:4326\")\n",
    "trips_start = gpd.sjoin(trips_start, hex_grid, how=\"inner\", rsuffix=\"7\" )\n",
    "trips_start = trips_start.loc[:, trips_start.columns != 'index_7']\n",
    "trips_start = gpd.sjoin(trips_start, hex_grid6, how=\"inner\", rsuffix=\"6\" )\n",
    "trips_start = trips_start.loc[:, trips_start.columns != 'index_6']\n",
    "trips_start = trips_start.rename(columns={'hex_id_left':'hex_id_7', 'centroid_left':'centroid_7'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give the trip feature just a start and end geoemtry \n",
    "TripsA = pd.merge(trips_start, trips_end, left_on='U_trip_ID',right_on='U_trip_ID', suffixes=('_start', '_end'))\n",
    "#rename geoemtry start to geoemtry so it can be make a geodataframe\n",
    "TripsA.rename(columns = {'geometry_start':'geometry'}, inplace = True)\n",
    "#set the geoemtry col\n",
    "TripsA = TripsA.set_geometry('geometry')\n",
    "TripsA = gpd.GeoDataFrame(TripsA, geometry='geometry', crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the lat and long of the start and end of the trip for the centroid of the hex polygon (zoom level 7)\n",
    "TripsA['source_long_7'] = TripsA.centroid_7_start.x\n",
    "TripsA['source_lat_7'] = TripsA.centroid_7_start.y\n",
    "TripsA['end_long_7'] = TripsA.centroid_7_end.x\n",
    "TripsA['end_lat_7'] = TripsA.centroid_7_end.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the lat and long of the start and end of the trip for the centroid of the hex polygon (zoom level 6)\n",
    "TripsA['source_long_6'] = TripsA.centroid_6_start.x\n",
    "TripsA['source_lat_6'] = TripsA.centroid_6_start.y\n",
    "TripsA['end_long_6'] = TripsA.centroid_6_end.x\n",
    "TripsA['end_lat_6'] = TripsA.centroid_6_end.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the labels from numbers to strings\n",
    "def mode_of_trans(row):\n",
    "    if row['labels'] == '1':\n",
    "        val = 'walk'\n",
    "    elif row['labels'] == '3':\n",
    "        val = 'bus'\n",
    "    elif row['labels'] == '4':\n",
    "        val = 'car'\n",
    "    else:\n",
    "        val = 'train'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the fuction to make string names\n",
    "TripsA['labels'] = TripsA.apply(mode_of_trans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hex_ids covering Washington CBD\n",
    "columns1 = ['862aa845fffffff','862aa844fffffff',  '862aa8447ffffff', '862aa8457ffffff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped trips by label at zoom level 6 with same OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the trips with the same start and end \n",
    "TripsA_grouped6 = TripsA.groupby(['hex_id_6_start','hex_id_6_end']).agg({'U_trip_ID':'count','overall_full_dist':'mean','total_trip_time':'mean','velo_mean':'mean','source_long_6':'first','source_lat_6':'first','end_long_6':'first','end_lat_6':'first'}).reset_index()\n",
    "#group the trips with the same start and end and labels\n",
    "TripsA_grouped6_labels = TripsA.groupby(['hex_id_6_start','hex_id_6_end','labels']).agg({'U_trip_ID':'count','overall_full_dist':'mean','total_trip_time':'mean','velo_mean':'mean','source_long_6':'first','source_lat_6':'first','end_long_6':'first','end_lat_6':'first'}).reset_index()\n",
    "#ensure there is more than for trips within a hex cell\n",
    "TripsA_grouped6_labels = TripsA_grouped6_labels[TripsA_grouped6_labels['U_trip_ID']>=4]\n",
    "#make the Uid a count label as this is what is represents\n",
    "TripsA_grouped6_labels = TripsA_grouped6_labels.rename(columns={'U_trip_ID': 'count'})\n",
    "#make the labels a string\n",
    "TripsA_grouped6_labels['labels'] = TripsA_grouped6_labels['labels'].astype(str)\n",
    "#make sure that the start is not the same as the end hex cell\n",
    "TripsA_grouped6_labels = TripsA_grouped6_labels[TripsA_grouped6_labels['hex_id_6_start'] != TripsA_grouped6_labels['hex_id_6_end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_everywhere = TripsA_grouped6_labels[TripsA_grouped6_labels['count']>5]\n",
    "All_everywhere.to_csv(r'All_everywhereFINAL.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top ten trips by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract from all the trips grouped with same origin and destination and label\n",
    "TripsA_grouped6_labelsTop10 = TripsA_grouped6_labels.groupby([\"labels\"]).apply(lambda x: x.sort_values([\"U_trip_ID\"], ascending = False)).reset_index(drop=True)\n",
    "#grab the top ten\n",
    "TripsA_grouped6_labelsTop10 = TripsA_grouped6_labelsTop10.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract trips at zoom level 7 for each transport mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cgroup trips with same start and end and label\n",
    "TripsA_grouped7 = TripsA.groupby(['hex_id_7_start','hex_id_7_end','labels']).agg({'U_trip_ID':'count','overall_full_dist':'mean','total_trip_time':'mean','velo_mean':'mean','source_long_7':'first','source_lat_7':'first','end_long_7':'first','end_lat_7':'first'}).reset_index()\n",
    "#end must be different to the start\n",
    "TripsA_grouped7 = TripsA_grouped7[TripsA_grouped7['hex_id_7_start'] != TripsA_grouped7['hex_id_7_end']]\n",
    "#rename the count \n",
    "TripsA_grouped7 = TripsA_grouped7.rename(columns={'U_trip_ID': 'count'})\n",
    "#extract each mode by label\n",
    "walk = TripsA_grouped7[TripsA_grouped7['labels']=='walk'].reset_index(drop=True)\n",
    "car = TripsA_grouped7[TripsA_grouped7['labels']=='car'].reset_index(drop=True)\n",
    "bus = TripsA_grouped7[TripsA_grouped7['labels']=='bus'].reset_index(drop=True)\n",
    "train = TripsA_grouped6_labels[TripsA_grouped6_labels['labels']=='train'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process to get trips by transport label without a specific direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process define in first cell is same in all modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break the start and end into a lsit column\n",
    "car['list']=car[['hex_id_7_start','hex_id_7_end']].values.tolist()\n",
    "#apply sorting to the list\n",
    "car['list']= car['list'].apply(sorted)\n",
    "#take the first in the list now as the start (not actually start but just the first we will take)\n",
    "car['hex_id_7_start'] = car['list'].str[0]\n",
    "#take the second in the list and make this the second geom\n",
    "car['hex_id_7_end'] = car['list'].str[1]\n",
    "#take the cars witht he same routes\n",
    "car = car.groupby(['hex_id_7_start','hex_id_7_end']).agg({'count':'sum','overall_full_dist':'mean','total_trip_time':'mean','velo_mean':'mean','source_long_7':'first','source_lat_7':'first','end_long_7':'first','end_lat_7':'first'}).reset_index()\n",
    "#sort the cars by count\n",
    "car = car.sort_values('count', ascending = False).head(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk['list']=walk[['hex_id_7_start','hex_id_7_end']].values.tolist()\n",
    "walk['list']= walk['list'].apply(sorted)\n",
    "walk['hex_id_7_start'] = walk['list'].str[0]\n",
    "walk['hex_id_7_end'] = walk['list'].str[1]\n",
    "walk = walk.groupby(['hex_id_7_start','hex_id_7_end']).agg({'count':'sum','total_trip_time':'mean','overall_full_dist':'mean','velo_mean':'mean','source_long_7':'first','source_lat_7':'first','end_long_7':'first','end_lat_7':'first'}).reset_index()\n",
    "walk = walk.sort_values('count', ascending = False).head(5).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['list']=train[['hex_id_6_start','hex_id_6_end']].values.tolist()\n",
    "train['list']= train['list'].apply(sorted)\n",
    "train['hex_id_6_start'] = train['list'].str[0]\n",
    "train['hex_id_6_end'] = train['list'].str[1]\n",
    "train = train.groupby(['hex_id_6_start','hex_id_6_end']).agg({'count':'sum','total_trip_time':'mean','overall_full_dist':'mean','velo_mean':'mean','source_long_6':'first','source_lat_6':'first','end_long_6':'first','end_lat_6':'first'}).reset_index()\n",
    "train = train.sort_values('count', ascending = False).head(5).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus['list']=bus[['hex_id_7_start','hex_id_7_end']].values.tolist()\n",
    "bus['list']= bus['list'].apply(sorted)\n",
    "bus['hex_id_7_start'] = bus['list'].str[0]\n",
    "bus['hex_id_7_end'] = bus['list'].str[1]\n",
    "bus = bus.groupby(['hex_id_7_start','hex_id_7_end']).agg({'count':'sum','total_trip_time':'mean','overall_full_dist':'mean','velo_mean':'mean','source_long_7':'first','source_lat_7':'first','end_long_7':'first','end_lat_7':'first'}).reset_index()\n",
    "bus = bus.sort_values('count', ascending = False).head(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract transport mode routes \n",
    "car.to_csv(r'cars2FINAL.csv', index = False)\n",
    "bus.to_csv(r'bus2FINAL.csv', index = False)\n",
    "walk.to_csv(r'walk2FINAL.csv', index = False)\n",
    "train.to_csv(r'trainsFINAL.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the trips going in and out of the city centre by transport mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take cars that start in the city centre\n",
    "TripsA_grouped6_out_city_car = car[car['hex_id_6_start'].isin(columns1)].sort_values('count', ascending = False)\n",
    "TripsA_grouped6_out_city_car = TripsA_grouped6_out_city_car[~TripsA_grouped6_out_city_car['hex_id_6_end'].isin(columns1)]\n",
    "#take buses that start in the city centre\n",
    "TripsA_grouped6_out_city_bus = bus[bus['hex_id_6_start'].isin(columns1)].sort_values('count', ascending = False)\n",
    "TripsA_grouped6_out_city_bus = TripsA_grouped6_out_city_bus[~TripsA_grouped6_out_city_bus['hex_id_6_end'].isin(columns1)]\n",
    "##take walker that start in the city centre\n",
    "TripsA_grouped6_out_city_walk = walk[walk['hex_id_6_start'].isin(columns1)].sort_values('count', ascending = False)\n",
    "TripsA_grouped6_out_city_walk = TripsA_grouped6_out_city_walk[~TripsA_grouped6_out_city_walk['hex_id_6_end'].isin(columns1)]\n",
    "##take trains that start in the city centre\n",
    "TripsA_grouped6_out_city_train = train[train['hex_id_6_start'].isin(columns1)].sort_values('count', ascending = False)\n",
    "TripsA_grouped6_out_city_train = TripsA_grouped6_out_city_train[~TripsA_grouped6_out_city_train['hex_id_6_end'].isin(columns1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all trips going in and out of city centre (not by transport mode)\n",
    "TripsA_grouped6_out_city = TripsA_grouped6[TripsA_grouped6['hex_id_6_start'].isin(columns1)].sort_values('U_trip_ID', ascending = False)\n",
    "TripsA_grouped6_out_city = TripsA_grouped6_out_city[~TripsA_grouped6_out_city['hex_id_6_end'].isin(columns1)]\n",
    "TripsA_grouped6_in_city = TripsA_grouped6[TripsA_grouped6['hex_id_6_end'].isin(columns1)].sort_values('U_trip_ID', ascending = False)\n",
    "TripsA_grouped6_in_city = TripsA_grouped6_in_city[~TripsA_grouped6_in_city['hex_id_6_start'].isin(columns1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take all trips into the city centre (not by transport mode)\n",
    "TripsA_grouped6_in_city = TripsA_grouped6_in_city.reset_index()\n",
    "TripsA_grouped6_in_city = TripsA_grouped6_in_city.sort_values('count', ascending = False).head(15)\n",
    "TripsA_grouped6_out_city = TripsA_grouped6_out_city.reset_index()\n",
    "TripsA_grouped6_out_city = TripsA_grouped6_out_city.sort_values('count', ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the labeled in and out of city centre trips\n",
    "TripsA_grouped6_out_city_car.to_csv(r'TripsA_grouped6_out_city_car.csv', index = False)\n",
    "TripsA_grouped6_out_city_bus.to_csv(r'TripsA_grouped6_out_city_bus.csv', index = False)\n",
    "TripsA_grouped6_out_city_walk.to_csv(r'TripsA_grouped6_out_city_walk.csv', index = False)\n",
    "TripsA_grouped6_out_city_train.to_csv(r'TripsA_grouped6_out_city_trains.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TripsA_grouped6_labels.to_csv(r'TripsA_grouped6_labelsFINAL.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the trips going in and out of the city at certain times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to label trips between specific hours (morning and evening peak travel)\n",
    "def label_time(row):\n",
    "    if (row['hour'] >= 6) & (row['hour'] <= 10)  :\n",
    "        val= 'am'\n",
    "    elif (row['hour'] >= 16) & (row['hour'] <= 20) :\n",
    "        val= 'pm'\n",
    "    else:\n",
    "        val= None\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function\n",
    "TripsA['time'] = TripsA.apply(label_time, axis=1) \n",
    "##only retain the trips on a weekday\n",
    "TripsA_weekday = TripsA[~TripsA['dayofweek'].isin(['sat','sun'])]\n",
    "#ensure that the start is not the same as the end\n",
    "TripsA_time = TripsA_weekday[TripsA_weekday['hex_id_7_start'] != TripsA_weekday['hex_id_7_end']]\n",
    "#rename the trip id column to a count\n",
    "TripsA_time = TripsA_time.rename(columns={'U_trip_ID': 'count'})\n",
    "#only keep the weekdays\n",
    "TripsA_time = TripsA_time[TripsA_time.time.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby trips with the same destination and the 2 times 'am' and 'pm'\n",
    "TripsA_time  = TripsA_time.groupby(['hex_id_7_end', 'time']).agg({'count':'count'}).reset_index()\n",
    "TripsA_time = TripsA_time[TripsA_time['count']>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract trips\n",
    "TripsA_time[TripsA_time['time']=='am'].to_csv(r'am_trips_weekFINAL.csv', index = False)\n",
    "TripsA_time[TripsA_time['time']=='pm'].to_csv(r'pm_trips_weekFINAL.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the trips going in and out of the city centre by any transport mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start cannot be same as end\n",
    "TripsA_grouped6 = TripsA_grouped6[TripsA_grouped6['hex_id_6_start'] != TripsA_grouped6['hex_id_6_end']]\n",
    "#rename the count col\n",
    "TripsA_grouped6 = TripsA_grouped6.rename(columns={'U_trip_ID': 'count'})\n",
    "#group all those going out of the city and sort by count\n",
    "TripsA_grouped6_out_city = TripsA_grouped6[TripsA_grouped6['hex_id_6_start'].isin(columns1)].sort_values('count', ascending = False)\n",
    "TripsA_grouped6_out_city = TripsA_grouped6_out_city[~TripsA_grouped6_out_city['hex_id_6_end'].isin(columns1)]\n",
    "#group those going into the city and sort by count\n",
    "TripsA_grouped6_in_city = TripsA_grouped6[TripsA_grouped6['hex_id_6_end'].isin(columns1)].sort_values('count', ascending = False)\n",
    "TripsA_grouped6_in_city = TripsA_grouped6_in_city[~TripsA_grouped6_in_city['hex_id_6_start'].isin(columns1)]\n",
    "TripsA_grouped6_in_city = TripsA_grouped6_in_city.reset_index(drop=True)\n",
    "TripsA_grouped6_out_city = TripsA_grouped6_out_city.reset_index(drop=True)\n",
    "#ensure they are over 4km trips\n",
    "TripsA_grouped6_out_cityTop10_far = TripsA_grouped6_out_city[TripsA_grouped6_out_city['overall_full_dist']>=4].head(10).reset_index(drop=True)\n",
    "TripsA_grouped6_in_cityTop10_far = TripsA_grouped6_in_city[TripsA_grouped6_in_city['overall_full_dist']>=4].head(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In and out of city centre by distance over 4km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TripsA_grouped6_in_cityTop10_far = TripsA_grouped6_in_cityTop10_far[TripsA_grouped6_in_cityTop10_far['count']>4]\n",
    "TripsA_grouped6_out_cityTop10_far = TripsA_grouped6_out_cityTop10_far[TripsA_grouped6_out_cityTop10_far['count']>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TripsA_grouped6_in_cityTop10_far.to_csv(r'TripsA_grouped6_in_city_dist10aFINAL.csv', index = False)\n",
    "TripsA_grouped6_out_cityTop10_far.to_csv(r'TripsA_grouped6_out_city_dist10aFINAL.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TripsA_grouped6_out_city_labels = TripsA_grouped6_labels[TripsA_grouped6_labels['hex_id_6_start'].isin(columns1)].sort_values('count', ascending = False)\n",
    "TripsA_grouped6_out_city_labels = TripsA_grouped6_out_city_labels[~TripsA_grouped6_out_city_labels['hex_id_6_end'].isin(columns1)]\n",
    "TripsA_grouped6_in_city_labels = TripsA_grouped6_labels[TripsA_grouped6_labels['hex_id_6_end'].isin(columns1)].sort_values('count', ascending = False)\n",
    "TripsA_grouped6_in_city_labels = TripsA_grouped6_in_city_labels[~TripsA_grouped6_in_city_labels['hex_id_6_start'].isin(columns1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TripsA_grouped6_in_city_labels.to_csv(r'TripsA_grouped6_in_city_labelsFINAL.csv', index = False)\n",
    "TripsA_grouped6_out_city_labels.to_csv(r'TripsA_grouped6_out_city_labelsFINAL.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
